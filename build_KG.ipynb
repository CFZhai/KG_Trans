{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spatial-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn.models import DeepGraphInfomax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "practical-replacement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "11.7\n",
      "Using GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Now, you can use `device` to send your tensors to the GPU or CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optional-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_net = pd.read_csv('./data/tmp_word_pair_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_net['study_a']= word_net['a_voc'].str.lower()\n",
    "word_net['remember_b']= word_net['b_voc'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_net.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_net.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_net.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_net_gp1 = word_net.groupby(['study_a']).sum()\n",
    "# word_net_gp2 = word_net.groupby(['remember_b']).sum()\n",
    "# word_net_gp = word_net_gp1+word_net_gp2\n",
    "# word_net_gp = word_net_gp/word_net_gp.shape[0]/2\n",
    "# word_net_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-compact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_thres1 = word_net.supp1.quantile(0.05)\n",
    "supp_thres2 = word_net.supp2.quantile(0.05)\n",
    "cond_thres1 =word_net.cond1.quantile(0.05)\n",
    "cond_thres2= word_net.cond2.quantile(0.05)\n",
    "lift_thres1 = 1\n",
    "lift_thres2 = 1\n",
    "lift_thres3 = 1\n",
    "p_thres = 0.05\n",
    "\n",
    "\n",
    "def filter_high_quality_dynamic_pair(df,p_thres, supp_thres1,supp_thres2,cond_thres1,cond_thres2,lift_thres1,lift_thres2):\n",
    "        df_temp = df[(df.supp1>supp_thres1) &(df.cond1>cond_thres1) &(df.lift1>lift_thres1) \\\n",
    "                 & (df.supp2>supp_thres2) &(df.cond2>cond_thres2) &(df.lift2>lift_thres2)  &(df.lift3>lift_thres3)]\n",
    "        #df_temp = df_temp[df_temp.p<p_thres]\n",
    "        df_temp=df_temp[df_temp['a_voc'] !=df_temp['b_voc'] ]\n",
    "        return df_temp\n",
    "    \n",
    "word_pair_filter = filter_high_quality_dynamic_pair(word_net, p_thres,supp_thres1,supp_thres2,cond_thres1,cond_thres2,lift_thres1,lift_thres2)\n",
    "\n",
    "#word_pair_filter.to_csv(\"./data/filtered_word_pairs.csv\",index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pair_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(word_pair_filter.a_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add chi_square for finding low p_value \n",
    "from scipy.stats import chi2_contingency\n",
    "prior_pair =word_net[word_net[\"a_voc\"] == word_net[\"b_voc\"]][[\"b_voc\", \"b_recall_cnt\", \"b_forget_cnt\"]]\n",
    "prior_pair = prior_pair.set_index(\"b_voc\")\n",
    "prior_pair = prior_pair.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chi2_p(x):\n",
    "    word_b = x[0]\n",
    "    recall_a = x[1]\n",
    "    forget_a = x[2]\n",
    "    #word_b, recall_a, forget_a = row[[\"b_voc\", \"b_recall_cnt\", \"b_forget_cnt\"]]\n",
    "    # 在单词a出现时，b记住的次数、忘记的次数\n",
    "    recall_b, forget_b = list(map(prior_pair[word_b].get, [\"b_recall_cnt\", \"b_forget_cnt\"]))\n",
    "    # b记住的次数、忘记的次数\n",
    "    data = [[recall_a, forget_a], [recall_b - recall_a, forget_b - forget_a]]\n",
    "    try:\n",
    "        _, p, _, _ = chi2_contingency(data)\n",
    "    except:\n",
    "        p = 1\n",
    "    return p \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "# from pandarallel import pandarallel\n",
    "\n",
    "batch_size = 100000\n",
    "num_rows = word_pair_filter.shape[0]\n",
    "num_chunks = num_rows // batch_size + 1\n",
    "# Create an empty list to store processed dataframes (optional, if you want to combine later)\n",
    "processed_dfs = []\n",
    "print(num_chunks)\n",
    "for i in range(num_chunks):\n",
    "    # Slice the DataFrame to get a chunk\n",
    "    print(\"iter:\",i)\n",
    "    df_chunk = word_pair_filter.iloc[i*batch_size : (i+1)*batch_size].copy()\n",
    "    \n",
    "    # Apply your function\n",
    "    df_chunk['p'] = df_chunk[[\"b_voc\", \"b_recall_cnt\", \"b_forget_cnt\"]].progress_apply(chi2_p, axis=1)\n",
    "    \n",
    "    # Store the processed chunk (optional)\n",
    "    processed_dfs.append(df_chunk)\n",
    "\n",
    "# Once all chunks have been processed, you can concatenate them\n",
    "word_pair_filter = pd.concat(processed_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "italian-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_pair_filter.to_csv(\"./data/filtered_word_pairs_unfiltered.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "simple-charge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_voc</th>\n",
       "      <th>b_voc</th>\n",
       "      <th>study_a</th>\n",
       "      <th>remember_b</th>\n",
       "      <th>b_recall_cnt</th>\n",
       "      <th>b_forget_cnt</th>\n",
       "      <th>supp1</th>\n",
       "      <th>supp2</th>\n",
       "      <th>cond1</th>\n",
       "      <th>cond2</th>\n",
       "      <th>lift1</th>\n",
       "      <th>lift2</th>\n",
       "      <th>lift3</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>April</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>april</td>\n",
       "      <td>catholic</td>\n",
       "      <td>59</td>\n",
       "      <td>45</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>0.5673</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>1.4964</td>\n",
       "      <td>1.4710</td>\n",
       "      <td>1.7566</td>\n",
       "      <td>9.826235e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>April</td>\n",
       "      <td>Christ</td>\n",
       "      <td>april</td>\n",
       "      <td>christ</td>\n",
       "      <td>98</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>1.4011</td>\n",
       "      <td>1.3868</td>\n",
       "      <td>1.6560</td>\n",
       "      <td>9.175321e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>April</td>\n",
       "      <td>Christian</td>\n",
       "      <td>april</td>\n",
       "      <td>christian</td>\n",
       "      <td>99</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7615</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>1.4324</td>\n",
       "      <td>1.3456</td>\n",
       "      <td>1.6068</td>\n",
       "      <td>1.775944e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April</td>\n",
       "      <td>Easter</td>\n",
       "      <td>april</td>\n",
       "      <td>easter</td>\n",
       "      <td>92</td>\n",
       "      <td>27</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.7731</td>\n",
       "      <td>0.7731</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1.4034</td>\n",
       "      <td>1.4034</td>\n",
       "      <td>1.6758</td>\n",
       "      <td>1.305838e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>April</td>\n",
       "      <td>Italian</td>\n",
       "      <td>april</td>\n",
       "      <td>italian</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>1.6188</td>\n",
       "      <td>1.5417</td>\n",
       "      <td>1.8409</td>\n",
       "      <td>4.101410e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_voc      b_voc study_a remember_b  b_recall_cnt  b_forget_cnt    supp1  \\\n",
       "0  April   Catholic   april   catholic            59            45  0.00005   \n",
       "1  April     Christ   april     christ            98            32  0.00007   \n",
       "2  April  Christian   april  christian            99            31  0.00007   \n",
       "3  April     Easter   april     easter            92            27  0.00006   \n",
       "5  April    Italian   april    italian            21             7  0.00001   \n",
       "\n",
       "    supp2   cond1   cond2   lift1   lift2   lift3             p  \n",
       "0  0.5577  0.5673  0.0074  1.4964  1.4710  1.7566  9.826235e-05  \n",
       "1  0.7462  0.7538  0.0123  1.4011  1.3868  1.6560  9.175321e-07  \n",
       "2  0.7154  0.7615  0.0118  1.4324  1.3456  1.6068  1.775944e-07  \n",
       "3  0.7731  0.7731  0.0117  1.4034  1.4034  1.6758  1.305838e-06  \n",
       "5  0.7143  0.7500  0.0025  1.6188  1.5417  1.8409  4.101410e-03  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pair_filter = word_pair_filter[['a_voc', 'b_voc','study_a', 'remember_b', 'b_recall_cnt', 'b_forget_cnt', 'supp1', 'supp2',\n",
    "       'cond1', 'cond2', 'lift1', 'lift2', 'lift3','p']][word_pair_filter.p<0.05]\n",
    "word_pair_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "twelve-insurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17236177 entries, 0 to 20404284\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   a_voc         object \n",
      " 1   b_voc         object \n",
      " 2   study_a       object \n",
      " 3   remember_b    object \n",
      " 4   b_recall_cnt  int64  \n",
      " 5   b_forget_cnt  int64  \n",
      " 6   supp1         float64\n",
      " 7   supp2         float64\n",
      " 8   cond1         float64\n",
      " 9   cond2         float64\n",
      " 10  lift1         float64\n",
      " 11  lift2         float64\n",
      " 12  lift3         float64\n",
      " 13  p             float64\n",
      "dtypes: float64(8), int64(2), object(4)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "word_pair_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "killing-utilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6685"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word_pair_filter.a_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "vertical-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pair_filter.to_csv(\"./data/filtered_word_pairs.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "outside-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PyTorch Geometric using the Deep Graph Infomax (DGI) method, which is a popular unsupervised method for learning node representations:\n",
    "    Deep Graph Infomax (DGI) is a method developed for unsupervised learning on graphs. The principle behind DGI is to maximize the mutual information between patch representations and corresponding high-level summaries of graphs, thereby capturing the global semantic information.\n",
    "'''\n",
    "# Encode the node names to integers\n",
    "le = LabelEncoder()\n",
    "nodes = pd.concat([word_pair_filter['study_a'], word_pair_filter['remember_b']])\n",
    "le.fit(nodes)\n",
    "word_pair_filter['study_a'] = le.transform(word_pair_filter['study_a'])\n",
    "word_pair_filter['remember_b'] = le.transform(word_pair_filter['remember_b'])\n",
    "\n",
    "label_to_original = {i: label for i, label in enumerate(le.classes_)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "outside-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edge_index tensor\n",
    "edges = word_pair_filter[['study_a', 'remember_b']].to_numpy().T\n",
    "edge_index = torch.tensor(edges, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mediterranean-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1512305/3299063126.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  word_net_gp1 = word_pair_filter.groupby(['study_a']).sum()\n",
      "/tmp/ipykernel_1512305/3299063126.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  word_net_gp2 = word_pair_filter.groupby(['remember_b']).sum()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_net_gp1 = word_pair_filter.groupby(['study_a']).sum()\n",
    "word_net_gp2 = word_pair_filter.groupby(['remember_b']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "systematic-solomon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remember_b</th>\n",
       "      <th>b_recall_cnt</th>\n",
       "      <th>b_forget_cnt</th>\n",
       "      <th>supp1</th>\n",
       "      <th>supp2</th>\n",
       "      <th>cond1</th>\n",
       "      <th>cond2</th>\n",
       "      <th>lift1</th>\n",
       "      <th>lift2</th>\n",
       "      <th>lift3</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study_a</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11877210</td>\n",
       "      <td>472200</td>\n",
       "      <td>201346</td>\n",
       "      <td>0.34443</td>\n",
       "      <td>2330.3668</td>\n",
       "      <td>2343.4091</td>\n",
       "      <td>24.7388</td>\n",
       "      <td>4672.6905</td>\n",
       "      <td>4646.5549</td>\n",
       "      <td>4729.3160</td>\n",
       "      <td>30.103605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14608426</td>\n",
       "      <td>892036</td>\n",
       "      <td>450569</td>\n",
       "      <td>0.68627</td>\n",
       "      <td>2772.2334</td>\n",
       "      <td>2886.7844</td>\n",
       "      <td>34.4980</td>\n",
       "      <td>5655.1331</td>\n",
       "      <td>5453.8447</td>\n",
       "      <td>6365.5551</td>\n",
       "      <td>15.558918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6120048</td>\n",
       "      <td>107320</td>\n",
       "      <td>87742</td>\n",
       "      <td>0.09959</td>\n",
       "      <td>734.5056</td>\n",
       "      <td>981.0143</td>\n",
       "      <td>12.0985</td>\n",
       "      <td>2802.7785</td>\n",
       "      <td>2113.5232</td>\n",
       "      <td>6284.8763</td>\n",
       "      <td>2.660573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5010755</td>\n",
       "      <td>151653</td>\n",
       "      <td>124088</td>\n",
       "      <td>0.14091</td>\n",
       "      <td>559.3964</td>\n",
       "      <td>769.5583</td>\n",
       "      <td>10.0518</td>\n",
       "      <td>2253.1123</td>\n",
       "      <td>1646.3749</td>\n",
       "      <td>5196.6668</td>\n",
       "      <td>1.409930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11104897</td>\n",
       "      <td>425208</td>\n",
       "      <td>237386</td>\n",
       "      <td>0.33856</td>\n",
       "      <td>2022.6403</td>\n",
       "      <td>2067.8426</td>\n",
       "      <td>20.2961</td>\n",
       "      <td>4300.8359</td>\n",
       "      <td>4219.9604</td>\n",
       "      <td>4832.3144</td>\n",
       "      <td>27.313952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         remember_b  b_recall_cnt  b_forget_cnt    supp1      supp2  \\\n",
       "study_a                                                               \n",
       "0          11877210        472200        201346  0.34443  2330.3668   \n",
       "1          14608426        892036        450569  0.68627  2772.2334   \n",
       "2           6120048        107320         87742  0.09959   734.5056   \n",
       "3           5010755        151653        124088  0.14091   559.3964   \n",
       "4          11104897        425208        237386  0.33856  2022.6403   \n",
       "\n",
       "             cond1    cond2      lift1      lift2      lift3          p  \n",
       "study_a                                                                  \n",
       "0        2343.4091  24.7388  4672.6905  4646.5549  4729.3160  30.103605  \n",
       "1        2886.7844  34.4980  5655.1331  5453.8447  6365.5551  15.558918  \n",
       "2         981.0143  12.0985  2802.7785  2113.5232  6284.8763   2.660573  \n",
       "3         769.5583  10.0518  2253.1123  1646.3749  5196.6668   1.409930  \n",
       "4        2067.8426  20.2961  4300.8359  4219.9604  4832.3144  27.313952  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_net_gp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "spread-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_a</th>\n",
       "      <th>b_recall_cnt</th>\n",
       "      <th>b_forget_cnt</th>\n",
       "      <th>supp1</th>\n",
       "      <th>supp2</th>\n",
       "      <th>cond1</th>\n",
       "      <th>cond2</th>\n",
       "      <th>lift1</th>\n",
       "      <th>lift2</th>\n",
       "      <th>lift3</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remember_b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2041549</td>\n",
       "      <td>129539</td>\n",
       "      <td>10939</td>\n",
       "      <td>0.07187</td>\n",
       "      <td>517.7436</td>\n",
       "      <td>534.6389</td>\n",
       "      <td>12.9193</td>\n",
       "      <td>624.0119</td>\n",
       "      <td>604.2944</td>\n",
       "      <td>670.5394</td>\n",
       "      <td>6.543360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17982069</td>\n",
       "      <td>316358</td>\n",
       "      <td>274801</td>\n",
       "      <td>0.30216</td>\n",
       "      <td>2470.5517</td>\n",
       "      <td>2865.9205</td>\n",
       "      <td>33.6287</td>\n",
       "      <td>8522.2332</td>\n",
       "      <td>7346.5565</td>\n",
       "      <td>13873.7099</td>\n",
       "      <td>8.088170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18413078</td>\n",
       "      <td>490757</td>\n",
       "      <td>482160</td>\n",
       "      <td>0.49737</td>\n",
       "      <td>2382.2476</td>\n",
       "      <td>2744.5355</td>\n",
       "      <td>50.1850</td>\n",
       "      <td>8662.9278</td>\n",
       "      <td>7519.4101</td>\n",
       "      <td>14204.8094</td>\n",
       "      <td>7.874369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>862304</td>\n",
       "      <td>62454</td>\n",
       "      <td>4840</td>\n",
       "      <td>0.03431</td>\n",
       "      <td>221.8084</td>\n",
       "      <td>230.2890</td>\n",
       "      <td>6.2497</td>\n",
       "      <td>263.7049</td>\n",
       "      <td>253.9945</td>\n",
       "      <td>282.3740</td>\n",
       "      <td>3.218194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1183202</td>\n",
       "      <td>92257</td>\n",
       "      <td>6599</td>\n",
       "      <td>0.05046</td>\n",
       "      <td>311.4980</td>\n",
       "      <td>321.2218</td>\n",
       "      <td>9.0613</td>\n",
       "      <td>365.3824</td>\n",
       "      <td>354.3232</td>\n",
       "      <td>389.9901</td>\n",
       "      <td>3.941677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             study_a  b_recall_cnt  b_forget_cnt    supp1      supp2  \\\n",
       "remember_b                                                             \n",
       "1            2041549        129539         10939  0.07187   517.7436   \n",
       "2           17982069        316358        274801  0.30216  2470.5517   \n",
       "3           18413078        490757        482160  0.49737  2382.2476   \n",
       "4             862304         62454          4840  0.03431   221.8084   \n",
       "5            1183202         92257          6599  0.05046   311.4980   \n",
       "\n",
       "                cond1    cond2      lift1      lift2       lift3         p  \n",
       "remember_b                                                                  \n",
       "1            534.6389  12.9193   624.0119   604.2944    670.5394  6.543360  \n",
       "2           2865.9205  33.6287  8522.2332  7346.5565  13873.7099  8.088170  \n",
       "3           2744.5355  50.1850  8662.9278  7519.4101  14204.8094  7.874369  \n",
       "4            230.2890   6.2497   263.7049   253.9945    282.3740  3.218194  \n",
       "5            321.2218   9.0613   365.3824   354.3232    389.9901  3.941677  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_net_gp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "authentic-asbestos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_forget_cnt</th>\n",
       "      <th>b_recall_cnt</th>\n",
       "      <th>cond1</th>\n",
       "      <th>cond2</th>\n",
       "      <th>lift1</th>\n",
       "      <th>lift2</th>\n",
       "      <th>lift3</th>\n",
       "      <th>p</th>\n",
       "      <th>remember_b</th>\n",
       "      <th>study_a</th>\n",
       "      <th>supp1</th>\n",
       "      <th>supp2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201346.0</td>\n",
       "      <td>472200.0</td>\n",
       "      <td>2343.4091</td>\n",
       "      <td>24.7388</td>\n",
       "      <td>4672.6905</td>\n",
       "      <td>4646.5549</td>\n",
       "      <td>4729.3160</td>\n",
       "      <td>30.103605</td>\n",
       "      <td>11877210.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.34443</td>\n",
       "      <td>2330.3668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461508.0</td>\n",
       "      <td>1021575.0</td>\n",
       "      <td>3421.4233</td>\n",
       "      <td>47.4173</td>\n",
       "      <td>6279.1450</td>\n",
       "      <td>6058.1391</td>\n",
       "      <td>7036.0945</td>\n",
       "      <td>22.102279</td>\n",
       "      <td>14608426.0</td>\n",
       "      <td>2041549.0</td>\n",
       "      <td>0.75814</td>\n",
       "      <td>3289.9770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>362543.0</td>\n",
       "      <td>423678.0</td>\n",
       "      <td>3846.9348</td>\n",
       "      <td>45.7272</td>\n",
       "      <td>11325.0117</td>\n",
       "      <td>9460.0797</td>\n",
       "      <td>20158.5862</td>\n",
       "      <td>10.748743</td>\n",
       "      <td>6120048.0</td>\n",
       "      <td>17982069.0</td>\n",
       "      <td>0.40175</td>\n",
       "      <td>3205.0573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606248.0</td>\n",
       "      <td>642410.0</td>\n",
       "      <td>3514.0938</td>\n",
       "      <td>60.2368</td>\n",
       "      <td>10916.0401</td>\n",
       "      <td>9165.7850</td>\n",
       "      <td>19401.4762</td>\n",
       "      <td>9.284299</td>\n",
       "      <td>5010755.0</td>\n",
       "      <td>18413078.0</td>\n",
       "      <td>0.63828</td>\n",
       "      <td>2941.6440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>242226.0</td>\n",
       "      <td>487662.0</td>\n",
       "      <td>2298.1316</td>\n",
       "      <td>26.5458</td>\n",
       "      <td>4564.5408</td>\n",
       "      <td>4473.9549</td>\n",
       "      <td>5114.6884</td>\n",
       "      <td>30.532146</td>\n",
       "      <td>11104897.0</td>\n",
       "      <td>862304.0</td>\n",
       "      <td>0.37287</td>\n",
       "      <td>2244.4487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b_forget_cnt  b_recall_cnt      cond1    cond2       lift1      lift2  \\\n",
       "0      201346.0      472200.0  2343.4091  24.7388   4672.6905  4646.5549   \n",
       "1      461508.0     1021575.0  3421.4233  47.4173   6279.1450  6058.1391   \n",
       "2      362543.0      423678.0  3846.9348  45.7272  11325.0117  9460.0797   \n",
       "3      606248.0      642410.0  3514.0938  60.2368  10916.0401  9165.7850   \n",
       "4      242226.0      487662.0  2298.1316  26.5458   4564.5408  4473.9549   \n",
       "\n",
       "        lift3          p  remember_b     study_a    supp1      supp2  \n",
       "0   4729.3160  30.103605  11877210.0         NaN  0.34443  2330.3668  \n",
       "1   7036.0945  22.102279  14608426.0   2041549.0  0.75814  3289.9770  \n",
       "2  20158.5862  10.748743   6120048.0  17982069.0  0.40175  3205.0573  \n",
       "3  19401.4762   9.284299   5010755.0  18413078.0  0.63828  2941.6440  \n",
       "4   5114.6884  30.532146  11104897.0    862304.0  0.37287  2244.4487  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_net_gp = word_net_gp1.add(word_net_gp2, fill_value=0)\n",
    "\n",
    "word_net_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "gothic-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_net_gp=word_net_gp.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "signal-riverside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes 6685\n"
     ]
    }
   ],
   "source": [
    "# Create node feature tensor by aggregating edge features\n",
    "num_nodes = nodes.nunique()\n",
    "print(\"num_nodes\",num_nodes)\n",
    "node_features =word_net_gp[['supp1', 'supp2','cond1', 'cond2', 'lift1', 'lift2', 'lift3','p']].values/word_net_gp.shape[0]\n",
    "\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "# Create the PyG Data object\n",
    "data = Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aquatic-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encoder definition\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels, cached=True)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "# Corruption function\n",
    "def corruption(x, edge_index):\n",
    "    return x[torch.randperm(x.size(0))], edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "threaded-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model and optimizer\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DeepGraphInfomax(\n",
    "    hidden_channels=64, encoder=Encoder(8, 64),  # updated number of input channels to 8\n",
    "    summary=lambda z, *args, **kwargs: torch.sigmoid(z.mean(dim=0)),\n",
    "    corruption=corruption).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "superb-millennium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n",
      "epoch: 21\n",
      "epoch: 22\n",
      "epoch: 23\n",
      "epoch: 24\n",
      "epoch: 25\n",
      "epoch: 26\n",
      "epoch: 27\n",
      "epoch: 28\n",
      "epoch: 29\n",
      "epoch: 30\n",
      "epoch: 31\n",
      "epoch: 32\n",
      "epoch: 33\n",
      "epoch: 34\n",
      "epoch: 35\n",
      "epoch: 36\n",
      "epoch: 37\n",
      "epoch: 38\n",
      "epoch: 39\n",
      "epoch: 40\n",
      "epoch: 41\n",
      "epoch: 42\n",
      "epoch: 43\n",
      "epoch: 44\n",
      "epoch: 45\n",
      "epoch: 46\n",
      "epoch: 47\n",
      "epoch: 48\n",
      "epoch: 49\n",
      "epoch: 50\n",
      "epoch: 51\n",
      "epoch: 52\n",
      "epoch: 53\n",
      "epoch: 54\n",
      "epoch: 55\n",
      "epoch: 56\n",
      "epoch: 57\n",
      "epoch: 58\n",
      "epoch: 59\n",
      "epoch: 60\n",
      "epoch: 61\n",
      "epoch: 62\n",
      "epoch: 63\n",
      "epoch: 64\n",
      "epoch: 65\n",
      "epoch: 66\n",
      "epoch: 67\n",
      "epoch: 68\n",
      "epoch: 69\n",
      "epoch: 70\n",
      "epoch: 71\n",
      "epoch: 72\n",
      "epoch: 73\n",
      "epoch: 74\n",
      "epoch: 75\n",
      "epoch: 76\n",
      "epoch: 77\n",
      "epoch: 78\n",
      "epoch: 79\n",
      "epoch: 80\n",
      "epoch: 81\n",
      "epoch: 82\n",
      "epoch: 83\n",
      "epoch: 84\n",
      "epoch: 85\n",
      "epoch: 86\n",
      "epoch: 87\n",
      "epoch: 88\n",
      "epoch: 89\n",
      "epoch: 90\n",
      "epoch: 91\n",
      "epoch: 92\n",
      "epoch: 93\n",
      "epoch: 94\n",
      "epoch: 95\n",
      "epoch: 96\n",
      "epoch: 97\n",
      "epoch: 98\n",
      "epoch: 99\n",
      "epoch: 100\n",
      "epoch: 101\n",
      "epoch: 102\n",
      "epoch: 103\n",
      "epoch: 104\n",
      "epoch: 105\n",
      "epoch: 106\n",
      "epoch: 107\n",
      "epoch: 108\n",
      "epoch: 109\n",
      "epoch: 110\n",
      "epoch: 111\n",
      "epoch: 112\n",
      "epoch: 113\n",
      "epoch: 114\n",
      "epoch: 115\n",
      "epoch: 116\n",
      "epoch: 117\n",
      "epoch: 118\n",
      "epoch: 119\n",
      "epoch: 120\n",
      "epoch: 121\n",
      "epoch: 122\n",
      "epoch: 123\n",
      "epoch: 124\n",
      "epoch: 125\n",
      "epoch: 126\n",
      "epoch: 127\n",
      "epoch: 128\n",
      "epoch: 129\n",
      "epoch: 130\n",
      "epoch: 131\n",
      "epoch: 132\n",
      "epoch: 133\n",
      "epoch: 134\n",
      "epoch: 135\n",
      "epoch: 136\n",
      "epoch: 137\n",
      "epoch: 138\n",
      "epoch: 139\n",
      "epoch: 140\n",
      "epoch: 141\n",
      "epoch: 142\n",
      "epoch: 143\n",
      "epoch: 144\n",
      "epoch: 145\n",
      "epoch: 146\n",
      "epoch: 147\n",
      "epoch: 148\n",
      "epoch: 149\n",
      "epoch: 150\n",
      "epoch: 151\n",
      "epoch: 152\n",
      "epoch: 153\n",
      "epoch: 154\n",
      "epoch: 155\n",
      "epoch: 156\n",
      "epoch: 157\n",
      "epoch: 158\n",
      "epoch: 159\n",
      "epoch: 160\n",
      "epoch: 161\n",
      "epoch: 162\n",
      "epoch: 163\n",
      "epoch: 164\n",
      "epoch: 165\n",
      "epoch: 166\n",
      "epoch: 167\n",
      "epoch: 168\n",
      "epoch: 169\n",
      "epoch: 170\n",
      "epoch: 171\n",
      "epoch: 172\n",
      "epoch: 173\n",
      "epoch: 174\n",
      "epoch: 175\n",
      "epoch: 176\n",
      "epoch: 177\n",
      "epoch: 178\n",
      "epoch: 179\n",
      "epoch: 180\n",
      "epoch: 181\n",
      "epoch: 182\n",
      "epoch: 183\n",
      "epoch: 184\n",
      "epoch: 185\n",
      "epoch: 186\n",
      "epoch: 187\n",
      "epoch: 188\n",
      "epoch: 189\n",
      "epoch: 190\n",
      "epoch: 191\n",
      "epoch: 192\n",
      "epoch: 193\n",
      "epoch: 194\n",
      "epoch: 195\n",
      "epoch: 196\n",
      "epoch: 197\n",
      "epoch: 198\n",
      "epoch: 199\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    print('epoch:',epoch)\n",
    "    data = data.to(device)\n",
    "    pos_z, neg_z, summary = model(data.x, data.edge_index)\n",
    "    loss = model.loss(pos_z, neg_z, summary)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "model.eval()\n",
    "# To get the node embeddings after training, you can use:\n",
    "with torch.no_grad():\n",
    "    z = model.encoder(data.x.to(device), data.edge_index.to(device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "coastal-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = z.cpu().numpy()\n",
    "\n",
    "# Create DataFrame from embeddings\n",
    "embeddings_df = pd.DataFrame(z, index=le.classes_)\n",
    "\n",
    "embeddings_df.columns = ['embed'+str(i+1) for i in range(embeddings_df.shape[1])]\n",
    "embeddings_df = embeddings_df.reset_index(drop=False)\n",
    "\n",
    "embeddings_df = embeddings_df.rename(columns ={\"index\":\"w\"})\n",
    "\n",
    "embeddings_df.to_csv('./data/KGembeddings.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "injured-boating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>embed1</th>\n",
       "      <th>embed2</th>\n",
       "      <th>embed3</th>\n",
       "      <th>embed4</th>\n",
       "      <th>embed5</th>\n",
       "      <th>embed6</th>\n",
       "      <th>embed7</th>\n",
       "      <th>embed8</th>\n",
       "      <th>embed9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed55</th>\n",
       "      <th>embed56</th>\n",
       "      <th>embed57</th>\n",
       "      <th>embed58</th>\n",
       "      <th>embed59</th>\n",
       "      <th>embed60</th>\n",
       "      <th>embed61</th>\n",
       "      <th>embed62</th>\n",
       "      <th>embed63</th>\n",
       "      <th>embed64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>-0.112005</td>\n",
       "      <td>0.175023</td>\n",
       "      <td>0.081303</td>\n",
       "      <td>0.119429</td>\n",
       "      <td>0.234358</td>\n",
       "      <td>-0.285393</td>\n",
       "      <td>0.088960</td>\n",
       "      <td>-0.084222</td>\n",
       "      <td>-0.146858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121453</td>\n",
       "      <td>0.046255</td>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.253145</td>\n",
       "      <td>0.250952</td>\n",
       "      <td>0.395841</td>\n",
       "      <td>0.263606</td>\n",
       "      <td>-0.024474</td>\n",
       "      <td>-0.125878</td>\n",
       "      <td>-0.034926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandon</td>\n",
       "      <td>-0.400461</td>\n",
       "      <td>0.727612</td>\n",
       "      <td>0.237638</td>\n",
       "      <td>0.407411</td>\n",
       "      <td>1.023871</td>\n",
       "      <td>-1.093308</td>\n",
       "      <td>0.371002</td>\n",
       "      <td>-0.282474</td>\n",
       "      <td>-0.603780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572360</td>\n",
       "      <td>0.213719</td>\n",
       "      <td>0.139102</td>\n",
       "      <td>0.971377</td>\n",
       "      <td>0.966684</td>\n",
       "      <td>1.702201</td>\n",
       "      <td>1.043585</td>\n",
       "      <td>-0.034144</td>\n",
       "      <td>-0.499250</td>\n",
       "      <td>-0.070479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdomen</td>\n",
       "      <td>-0.485593</td>\n",
       "      <td>1.103594</td>\n",
       "      <td>0.264719</td>\n",
       "      <td>0.511833</td>\n",
       "      <td>1.521983</td>\n",
       "      <td>-1.432766</td>\n",
       "      <td>0.503473</td>\n",
       "      <td>-0.349383</td>\n",
       "      <td>-0.807522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910728</td>\n",
       "      <td>0.306264</td>\n",
       "      <td>0.270944</td>\n",
       "      <td>1.298496</td>\n",
       "      <td>1.351456</td>\n",
       "      <td>2.541386</td>\n",
       "      <td>1.477359</td>\n",
       "      <td>0.069351</td>\n",
       "      <td>-0.689769</td>\n",
       "      <td>-0.026549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abide</td>\n",
       "      <td>-0.479631</td>\n",
       "      <td>1.098984</td>\n",
       "      <td>0.261993</td>\n",
       "      <td>0.506807</td>\n",
       "      <td>1.512208</td>\n",
       "      <td>-1.418678</td>\n",
       "      <td>0.499232</td>\n",
       "      <td>-0.345371</td>\n",
       "      <td>-0.799597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907186</td>\n",
       "      <td>0.303954</td>\n",
       "      <td>0.270819</td>\n",
       "      <td>1.286539</td>\n",
       "      <td>1.342442</td>\n",
       "      <td>2.527811</td>\n",
       "      <td>1.467622</td>\n",
       "      <td>0.073551</td>\n",
       "      <td>-0.683922</td>\n",
       "      <td>-0.024235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ability</td>\n",
       "      <td>-0.257335</td>\n",
       "      <td>0.465007</td>\n",
       "      <td>0.156881</td>\n",
       "      <td>0.264888</td>\n",
       "      <td>0.649716</td>\n",
       "      <td>-0.698882</td>\n",
       "      <td>0.233898</td>\n",
       "      <td>-0.185201</td>\n",
       "      <td>-0.381730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361201</td>\n",
       "      <td>0.133533</td>\n",
       "      <td>0.090380</td>\n",
       "      <td>0.622238</td>\n",
       "      <td>0.620555</td>\n",
       "      <td>1.080868</td>\n",
       "      <td>0.667867</td>\n",
       "      <td>-0.024280</td>\n",
       "      <td>-0.319865</td>\n",
       "      <td>-0.049535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         w    embed1    embed2    embed3    embed4    embed5    embed6  \\\n",
       "0        a -0.112005  0.175023  0.081303  0.119429  0.234358 -0.285393   \n",
       "1  abandon -0.400461  0.727612  0.237638  0.407411  1.023871 -1.093308   \n",
       "2  abdomen -0.485593  1.103594  0.264719  0.511833  1.521983 -1.432766   \n",
       "3    abide -0.479631  1.098984  0.261993  0.506807  1.512208 -1.418678   \n",
       "4  ability -0.257335  0.465007  0.156881  0.264888  0.649716 -0.698882   \n",
       "\n",
       "     embed7    embed8    embed9  ...   embed55   embed56   embed57   embed58  \\\n",
       "0  0.088960 -0.084222 -0.146858  ...  0.121453  0.046255  0.027163  0.253145   \n",
       "1  0.371002 -0.282474 -0.603780  ...  0.572360  0.213719  0.139102  0.971377   \n",
       "2  0.503473 -0.349383 -0.807522  ...  0.910728  0.306264  0.270944  1.298496   \n",
       "3  0.499232 -0.345371 -0.799597  ...  0.907186  0.303954  0.270819  1.286539   \n",
       "4  0.233898 -0.185201 -0.381730  ...  0.361201  0.133533  0.090380  0.622238   \n",
       "\n",
       "    embed59   embed60   embed61   embed62   embed63   embed64  \n",
       "0  0.250952  0.395841  0.263606 -0.024474 -0.125878 -0.034926  \n",
       "1  0.966684  1.702201  1.043585 -0.034144 -0.499250 -0.070479  \n",
       "2  1.351456  2.541386  1.477359  0.069351 -0.689769 -0.026549  \n",
       "3  1.342442  2.527811  1.467622  0.073551 -0.683922 -0.024235  \n",
       "4  0.620555  1.080868  0.667867 -0.024280 -0.319865 -0.049535  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "small-whale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6685 entries, 0 to 6684\n",
      "Data columns (total 65 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   w        6685 non-null   object \n",
      " 1   embed1   6685 non-null   float32\n",
      " 2   embed2   6685 non-null   float32\n",
      " 3   embed3   6685 non-null   float32\n",
      " 4   embed4   6685 non-null   float32\n",
      " 5   embed5   6685 non-null   float32\n",
      " 6   embed6   6685 non-null   float32\n",
      " 7   embed7   6685 non-null   float32\n",
      " 8   embed8   6685 non-null   float32\n",
      " 9   embed9   6685 non-null   float32\n",
      " 10  embed10  6685 non-null   float32\n",
      " 11  embed11  6685 non-null   float32\n",
      " 12  embed12  6685 non-null   float32\n",
      " 13  embed13  6685 non-null   float32\n",
      " 14  embed14  6685 non-null   float32\n",
      " 15  embed15  6685 non-null   float32\n",
      " 16  embed16  6685 non-null   float32\n",
      " 17  embed17  6685 non-null   float32\n",
      " 18  embed18  6685 non-null   float32\n",
      " 19  embed19  6685 non-null   float32\n",
      " 20  embed20  6685 non-null   float32\n",
      " 21  embed21  6685 non-null   float32\n",
      " 22  embed22  6685 non-null   float32\n",
      " 23  embed23  6685 non-null   float32\n",
      " 24  embed24  6685 non-null   float32\n",
      " 25  embed25  6685 non-null   float32\n",
      " 26  embed26  6685 non-null   float32\n",
      " 27  embed27  6685 non-null   float32\n",
      " 28  embed28  6685 non-null   float32\n",
      " 29  embed29  6685 non-null   float32\n",
      " 30  embed30  6685 non-null   float32\n",
      " 31  embed31  6685 non-null   float32\n",
      " 32  embed32  6685 non-null   float32\n",
      " 33  embed33  6685 non-null   float32\n",
      " 34  embed34  6685 non-null   float32\n",
      " 35  embed35  6685 non-null   float32\n",
      " 36  embed36  6685 non-null   float32\n",
      " 37  embed37  6685 non-null   float32\n",
      " 38  embed38  6685 non-null   float32\n",
      " 39  embed39  6685 non-null   float32\n",
      " 40  embed40  6685 non-null   float32\n",
      " 41  embed41  6685 non-null   float32\n",
      " 42  embed42  6685 non-null   float32\n",
      " 43  embed43  6685 non-null   float32\n",
      " 44  embed44  6685 non-null   float32\n",
      " 45  embed45  6685 non-null   float32\n",
      " 46  embed46  6685 non-null   float32\n",
      " 47  embed47  6685 non-null   float32\n",
      " 48  embed48  6685 non-null   float32\n",
      " 49  embed49  6685 non-null   float32\n",
      " 50  embed50  6685 non-null   float32\n",
      " 51  embed51  6685 non-null   float32\n",
      " 52  embed52  6685 non-null   float32\n",
      " 53  embed53  6685 non-null   float32\n",
      " 54  embed54  6685 non-null   float32\n",
      " 55  embed55  6685 non-null   float32\n",
      " 56  embed56  6685 non-null   float32\n",
      " 57  embed57  6685 non-null   float32\n",
      " 58  embed58  6685 non-null   float32\n",
      " 59  embed59  6685 non-null   float32\n",
      " 60  embed60  6685 non-null   float32\n",
      " 61  embed61  6685 non-null   float32\n",
      " 62  embed62  6685 non-null   float32\n",
      " 63  embed63  6685 non-null   float32\n",
      " 64  embed64  6685 non-null   float32\n",
      "dtypes: float32(64), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "embeddings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-coral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cz",
   "language": "python",
   "name": "cz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
